{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Run Basic Data Quality Checks\n",
    "- Before we begin any cleaning, we need to understand the quality of the data we're working with. So the first step involves assessing the current state of your data.\n",
    "- We need to identify:\n",
    "Missing values in each column.\n",
    "- Duplicate rows\n",
    "- Basic data characteristics\n",
    "- Let's start with some essential quality checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# df= pd.read_csv(r'mobiles_dataset.csv')\n",
    "def check_data_quality(df):\n",
    "    # Store initial data quality metrics\n",
    "    quality_report = {\n",
    "        'missing_values': df.isnull().sum().to_dict(),\n",
    "        'duplicates': df.duplicated().sum(),\n",
    "        'total_rows': len(df),\n",
    "        'memory_usage': df.memory_usage().sum() / 1024**2  # in MB\n",
    "    }\n",
    "    return quality_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Standardize Data Types.\n",
    "- One of the most common issues in raw data is inconsistent data types. \n",
    "- For example, dates might be stored as strings, or numeric values might include currency symbols, and the like.\n",
    "- So as the next step, we ensure all fields have the right/expected data types. This includes:\n",
    "- Converting string dates to datetime objects\n",
    "- Identifying and converting numeric strings to actual numbers\n",
    "- Ensuring categorical variables are properly encoded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def standardize_datatypes(df):\n",
    "    for column in df.columns:\n",
    "        # Try converting string dates to datetime\n",
    "        if df[column].dtype == 'object':\n",
    "            try:\n",
    "                df[column] = pd.to_datetime(df[column])\n",
    "                print(f\"Converted {column} to datetime\")\n",
    "            except ValueError:\n",
    "                # Try converting to numeric if datetime fails\n",
    "                try:\n",
    "                    df[column] = pd.to_numeric(df[column].str.replace('$', '').str.replace(',', ''))\n",
    "                    print(f\"Converted {column} to numeric\")\n",
    "                except:\n",
    "                    pass\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Handle Missing Values\n",
    " \n",
    "- Missing values can significantly impact our analysis. Rather than dropping data records with missing values, we can use imputation strategies:\n",
    "\n",
    "- Using median imputation for numeric columns\n",
    "Applying mode imputation for categorical data\n",
    "Maintaining the statistical properties of the dataset while filling gaps\n",
    "Here’s how we can impute missing values in both numeric and categorical columns:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def handle_missing_values(df):\n",
    "    # Handle numeric columns\n",
    "    numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    if len(numeric_columns) > 0:\n",
    "        num_imputer = SimpleImputer(strategy='median')\n",
    "        df[numeric_columns] = num_imputer.fit_transform(df[numeric_columns])\n",
    "    \n",
    "    # Handle categorical columns\n",
    "    categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "    if len(categorical_columns) > 0:\n",
    "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        df[categorical_columns] = cat_imputer.fit_transform(df[categorical_columns])\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Detect and Handle Outliers\n",
    "- Outliers can skew our analysis, so we need to handle them carefully.\n",
    "You need domain knowledge to decide on “what” might actually be outliers.\n",
    "Here's an approach using the Interquartile Range (IQR) method:\n",
    "- Calculate Interquartile Range (IQR) for numeric columns\n",
    "Identify values beyond 1.5 * IQR from quartiles\n",
    "Apply capping to extreme values rather than removing them\n",
    "This preserves data while managing extreme values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def remove_outliers(df):\n",
    "    numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    outliers_removed = {}\n",
    "    \n",
    "    for column in numeric_columns:\n",
    "        Q1 = df[column].quantile(0.25)\n",
    "        Q3 = df[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        # Count outliers before removing\n",
    "        outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)].shape[0]\n",
    "        \n",
    "        # Cap the values instead of removing them\n",
    "        df[column] = df[column].clip(lower=lower_bound, upper=upper_bound)\n",
    "        \n",
    "        if outliers > 0:\n",
    "            outliers_removed[column] = outliers\n",
    "            \n",
    "    return df, outliers_removed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Step 5: Validate the Results\n",
    "- After cleaning, we need to verify that our pipeline worked as expected:\n",
    "- Confirm no remaining missing values\n",
    " - Check for any remaining duplicates\n",
    "- Validate data integrity and consistency\n",
    "- Generate a comprehensive cleaning report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_cleaning(df, original_shape, cleaning_report):\n",
    "    validation_results = {\n",
    "        'rows_remaining': len(df),\n",
    "        'missing_values_remaining': df.isnull().sum().sum(),\n",
    "        'duplicates_remaining': df.duplicated().sum(),\n",
    "        'data_loss_percentage': (1 - len(df)/original_shape[0]) * 100\n",
    "    }\n",
    "    \n",
    "    # Add validation results to the cleaning report\n",
    "    cleaning_report['validation'] = validation_results\n",
    "    return cleaning_report\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, let's put it all together in a complete pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def automated_cleaning_pipeline(df):\n",
    "    # Store original shape for reporting\n",
    "    original_shape = df.shape\n",
    "    \n",
    "    # Initialize cleaning report\n",
    "    cleaning_report = {}\n",
    "    \n",
    "    # Execute each step and collect metrics\n",
    "    cleaning_report['initial_quality'] = check_data_quality(df)\n",
    "    \n",
    "    df = standardize_datatypes(df)\n",
    "    df = handle_missing_values(df)\n",
    "    df, outliers = remove_outliers(df)\n",
    "    cleaning_report['outliers_removed'] = outliers\n",
    "    \n",
    "    # Validate and finalize report\n",
    "    cleaning_report = validate_cleaning(df, original_shape, cleaning_report)\n",
    "    \n",
    "    return df, cleaning_report\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
